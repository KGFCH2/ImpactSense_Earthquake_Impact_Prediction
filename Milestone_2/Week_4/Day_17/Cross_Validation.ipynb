{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8f078a",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "`Cross-validation` is a robust method to evaluate a machine learning model’s performance by splitting the data into multiple subsets (folds) and training/testing the model on different combinations of these subsets. It helps to assess how the model generalizes to unseen data and reduces variance from random train-test splits.\n",
    "\n",
    "Example: K-Fold Cross-Validation\n",
    "  - Split data into k (e.g., 5) roughly equal parts.\n",
    "\n",
    "  - For each fold: use one part as validation, remaining k-1 parts to train.\n",
    "\n",
    "  - Repeat for all folds and average performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb34abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE: 0.2598\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation with scikit-learn to evaluate a regression model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X = np.random.rand(100, 10)\n",
    "y = np.random.rand(100)\n",
    "# Define model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "# Output the average score\n",
    "print(f\"Average MAE: {-np.mean(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6dc388",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Machine learning models have hyperparameters—external settings that govern training (e.g., tree depth, learning rate). Hyperparameter tuning aims to find the optimal set of hyperparameters that maximize the model’s predictive performance.\n",
    "\n",
    "Methods: \n",
    "  - Manual Search: Try different values based on intuition.\n",
    "\n",
    "  - Grid Search: Exhaustive search over specified parameter values.\n",
    "\n",
    "  - Random Search: Randomly sample hyperparameter combinations.\n",
    "\n",
    "  - Bayesian Optimization: Probabilistic model-based search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d28d3",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "`GridSearchCV` automates hyperparameter tuning with cross-validation. It performs exhaustive search over specified hyperparameter combinations and selects the best based on cross-validated scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06818493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'n_estimators': 100}\n",
      "Best CV MAE: 0.2483\n"
     ]
    }
   ],
   "source": [
    "# Example: Tuning Random Forest Parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20]\n",
    "}\n",
    "# Sample data\n",
    "X_train = np.random.rand(100, 10)\n",
    "y_train = np.random.rand(100)\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV MAE: {-grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ce9db",
   "metadata": {},
   "source": [
    "### SHAP Values (SHapley Additive exPlanations)\n",
    "\n",
    "`SHAP` values provide a unified approach to interpret machine learning model predictions by assigning each feature a contribution value (positive or negative) for a specific prediction. SHAP leverages cooperative game theory (Shapley values) to quantify feature importance consistently.\n",
    "\n",
    "Benefits:\n",
    "  - Model-agnostic interpretation (works for tree-based, neural nets, others).\n",
    "\n",
    "  - Local explanations (for individual predictions).\n",
    "\n",
    "  - Global explanations (feature importance across dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade8d4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Program' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a43ee68",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This notebook succinctly covers fundamental practices in model evaluation (cross-validation), parameter optimization (GridSearchCV), and model interpretability (SHAP), supported with practical Python code examples using scikit-learn and XGBoost. These serve as essential techniques for building, tuning, and explaining predictive models effectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
